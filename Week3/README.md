# week3ë¦´ë ˆì´

# ê¸°ëŠ¥ 1 : ì–¼êµ´ ì‚¬ì§„ ì˜ë¼ë‚´ê¸°

S002_ê°•ë³‘ë¯¼

S017 ë°•ì„±ë¯¼

S028 ì‹ ì€ì§€

S040 ì´ì€ì •

S055 ì¡°ìˆ˜ì •

- ë§¤ìš° ê¸´ ì½”ë“œ ì£¼ì˜

    ```swift
    import UIKit
    import Vision
    class ViewController: UIViewController {
      @IBOutlet weak var lableView: UILabel!
      @IBOutlet weak var buttonView: UIButton!
      @IBOutlet weak var imageView: UIImageView!
      @IBOutlet weak var filterBook: UIImageView!

      override func viewDidLoad() {
        lableView.text = â€œê°•ë³‘ë¯¼â€
        super.viewDidLoad()
        imageView.downloaded(from: â€œhttps://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile27.uf.tistory.com%2Fimage%2F99719E475A4DB112087077â€)
        // Do any additional setup after loading the view.
      }
      @IBAction func pressedButton(_ sender: UIButton) {
        let rect = CGRect(x: 300.0, y: 300.0, width: 40.0, height: 40.0)
        imageView.image?.draw(in: rect)
      }
      @IBAction func pictureChangeButton(_ sender: UIButton) {
        if let inputImage = imageView.image {
          let ciImage = CIImage(cgImage: inputImage.cgImage!)
          let options = [CIDetectorAccuracy: CIDetectorAccuracyHigh]
          let faceDetector = CIDetector(ofType: CIDetectorTypeFace, context: nil, options: options)!
          let faces = faceDetector.features(in: ciImage)
          if let face = faces.first as? CIFaceFeature {
            print(â€œFound face at \(face.bounds)â€œ)
            if face.hasLeftEyePosition {
              print(â€œFound left eye at \(face.leftEyePosition)â€œ)
            }
            if face.hasRightEyePosition {
              print(â€œFound right eye at \(face.rightEyePosition)â€œ)
            }
            if face.hasMouthPosition {
              print(â€œFound mouth at \(face.mouthPosition)â€œ)
            }
            let cropped = ciImage.cropped(to: face.bounds)
            print(cropped)
    //        let croppedCGImage:CGImage = (inputImage.cgImage?.cropping(to: face.bounds))!
            let croppedImage = UIImage(ciImage: cropped)
            print(croppedImage)
            imageView.image = croppedImage
          }
          //      imageView.frame = CGRect(x: 0, y: 0, width: 500, height: 500) // The size of the background image
          //
          //      filterBook.frame = CGRect(x: 150, y: 300, width: 50, height: 50)
          //      imageView.addSubview(filterBook)
        }
      }
      func cropImage1(image: UIImage, rect: CGRect) -> UIImage {
        let cgImage = image.cgImage! // better to write â€œguardâ€ in realm app
        let croppedCGImage = cgImage.cropping(to: rect)
        return UIImage(cgImage: croppedCGImage!)
      }
      private func drawOccurrencesOnImage(_ occurrences: [CGRect], _ image: UIImage) -> UIImage? {
        let imageSize = image.size
        let scale: CGFloat = 0.0
        UIGraphicsBeginImageContextWithOptions(imageSize, false, scale)
        image.draw(at: CGPoint.zero)
        let ctx = UIGraphicsGetCurrentContext()
        ctx?.addRects(occurrences)
        ctx?.setStrokeColor(UIColor.red.cgColor)
        ctx?.setLineWidth(2.0)
        ctx?.strokePath()
        let drawnImage = UIGraphicsGetImageFromCurrentImageContext()
        UIGraphicsEndImageContext()
        return drawnImage
      }
    }
    extension UIImageView {
      func downloaded(from url: URL, contentMode mode: UIView.ContentMode = .scaleAspectFit) {
        contentMode = mode
        URLSession.shared.dataTask(with: url) { data, response, error in
          guard
            let httpURLResponse = response as? HTTPURLResponse, httpURLResponse.statusCode == 200,
            let mimeType = response?.mimeType, mimeType.hasPrefix(â€œimageâ€),
            let data = data, error == nil,
            let image = UIImage(data: data)
            else { return }
          DispatchQueue.main.async() { [weak self] in
            self?.image = image
          }
        }.resume()
      }
      func downloaded(from link: String, contentMode mode: UIView.ContentMode = .scaleAspectFit) {
        guard let url = URL(string: link) else { return }
        downloaded(from: url, contentMode: mode)
      }
    }
    ```

    ```swift
    import UIKit

    class ViewController: UIViewController {

        @IBOutlet weak var insertButton: UIButton!
        @IBOutlet weak var extractButton: UIButton!
        @IBOutlet weak var imageView: UIImageView!
        
        override func viewDidLoad() {
            super.viewDidLoad()
            // Do any additional setup after loading the view.
        }
        
        @IBAction func insertImage(_ sender: UIButton) {
            imageView.downloaded(from: "https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile27.uf.tistory.com%2Fimage%2F99719E475A4DB112087077")
        }
        
        @IBAction func extractImage(_ sender: UIButton) {
            print("pressed")
            let image = imageView.getFaceImage()
            imageView.image = image
        }

    }

    extension UIView {

    func getFaceImage() -> UIImage? {
           let faceDetectorOptions: [String: AnyObject] = [CIDetectorAccuracy: CIDetectorAccuracyHigh as AnyObject]

           let faceDetector: CIDetector = CIDetector(ofType: CIDetectorTypeFace, context: nil, options: faceDetectorOptions)!

           let viewScreenShotImage = generateScreenShot(scaleTo: 1.0)

           if viewScreenShotImage.cgImage != nil {
               let sourceImage = CIImage(cgImage: viewScreenShotImage.cgImage!)
               let features = faceDetector.features(in: sourceImage)
               if features.count > 0 {
                   var faceBounds = CGRect.zero
                   var faceImage: UIImage?
                   for feature in features as! [CIFaceFeature] {
                       faceBounds = feature.bounds
                    let faceCroped: CIImage = sourceImage.cropped(to: faceBounds)
                       //faceImage = UIImage(ciImage: faceCroped)
                        let cgImage: CGImage = {
                           let context = CIContext(options: nil)
                           return context.createCGImage(faceCroped, from: faceCroped.extent)!
                        }()
                        faceImage = UIImage(cgImage: cgImage)
                   }
                   return faceImage
               } else {
                   return nil
               }
           } else {
               return nil
           }
    }

    func generateScreenShot(scaleTo: CGFloat = 3.0) -> UIImage {
           let rect = self.bounds
           UIGraphicsBeginImageContextWithOptions(rect.size, false, 0.0)
           let context = UIGraphicsGetCurrentContext()
           self.layer.render(in: context!)
           let screenShotImage = UIGraphicsGetImageFromCurrentImageContext()!
           UIGraphicsEndImageContext()
           let aspectRatio = screenShotImage.size.width / screenShotImage.size.height
    //       let resizedScreenShotImage = screenShotImage.scaleImage(toSize: CGSize(width: self.bounds.size.height * aspectRatio * scaleTo, height: self.bounds.size.height * scaleTo))
    //       return resizedScreenShotImage!
        return screenShotImage
        }
    }

    extension UIImageView {
      func downloaded(from url: URL, contentMode mode: UIView.ContentMode = .scaleAspectFit) {
        contentMode = mode
        URLSession.shared.dataTask(with: url) { data, response, error in
          guard
            let httpURLResponse = response as? HTTPURLResponse, httpURLResponse.statusCode == 200,
            let mimeType = response?.mimeType, mimeType.hasPrefix("image"),
            let data = data, error == nil,
            let image = UIImage(data: data)
            else { return }
          DispatchQueue.main.async() { [weak self] in
            self?.image = image
          }
        }.resume()
      }
      func downloaded(from link: String, contentMode mode: UIView.ContentMode = .scaleAspectFit) {
        guard let url = URL(string: link) else { return }
        downloaded(from: url, contentMode: mode)
      }
    }
    ```

[Open the native iOS Camera and Photo Library in Swift](http://xstutorials.com/open-native-ios-camera-and-photo-library-in-swift/)

[Face Detection Tutorial Using the Vision Framework for iOS](https://www.raywenderlich.com/1163620-face-detection-tutorial-using-the-vision-framework-for-ios)

[Image Processing in iOS Part 1: Raw Bitmap Modification](https://www.raywenderlich.com/2335-image-processing-in-ios-part-1-raw-bitmap-modification#toc-anchor-009)

# ê¸°ëŠ¥ 2 : í‘ë°± â†” ì»¬ëŸ¬ ì „í™˜

S047_ì¥ì§€ì„

S038_ì´ìƒìœ¤

S033 ì˜¤ë™ê±´

### Deepai API ì‚¬ìš©ë²•

[Image Colorization](https://deepai.org/machine-learning-model/colorizer)

1. íšŒì›ê°€ì… í›„ api-key ë°œê¸‰
2. Alamofireë¥¼ ì´ìš©í•œ postìš”ì²­
3. postìš”ì²­ ì˜ˆì‹œ
- URL

    [https://api.deepai.org/api/colorizer](https://api.deepai.org/api/colorizer)

- method

    'post'

- Header

     key : 'api-key', value : 'ë°œê¸‰ëœ api key'

- form data

    key : 'image', value : image data

4. ì‘ë‹µ ì˜ˆì‹œ

{
"id": "4ba07365-5b6e-4a24-8b8b-993f712344cd6",
"output_url": "https://output url "
}

![Untitled](https://user-images.githubusercontent.com/28242038/90348929-d012ad80-e072-11ea-8230-f5df2b9bcff0.png)

5. ì‚¬ì§„ ì˜ˆì‹œ

í‘ë°±ì‚¬ì§„ â†’ ì»¬ëŸ¬ì‚¬ì§„ ë³€ê²½ë¨ ğŸ’¯

<img src="https://user-images.githubusercontent.com/28242038/90348963-ed477c00-e072-11ea-88d8-5c0e2491cdc9.png" alt="Untitled 1" style="zoom:50%;" />
<img src="https://user-images.githubusercontent.com/28242038/90348968-f0db0300-e072-11ea-882c-8745614812ed.png" alt="Untitled 2" style="zoom:50%;" />

### Alamofire

- Alamofire ë€
    - Appleì˜ Foundation networking ê¸°ë°˜ìœ¼ë¡œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µ
    - iOS, macOSë¥¼ ìœ„í•œ ìŠ¤ìœ„í”„íŠ¸ ê¸°ë°˜ HTTP ë„¤íŠ¸ì›Œí‚¹ ë¼ì´ë¸ŒëŸ¬ë¦¬
    - ì¼ë°˜ì ì¸ ë„¤íŠ¸ì›Œí‚¹ ì‘ì—…ì„ ë‹¨ìˆœí™”

- ê¸°ëŠ¥
    - Request / Response method
    - JSON Parameter
    - Response serialization
    - Authentication ë“±.. ë§ì€ ê¸°ëŠ¥ ë‚´í¬

- ê¸°ì´ˆ ì‚¬ìš©ë²•

[Swift, Alamofireê°€ ë¬´ì—‡ì¸ì§€, ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì•Œì•„ë´…ë‹ˆë‹¤](https://devmjun.github.io/archive/Alamofire)

### ì‹œì‘

- PodFile ìƒì„± - ê°€ì¥ ìƒìœ„ì—

![Untitled 3](https://user-images.githubusercontent.com/28242038/90349007-1700a300-e073-11ea-998b-30df4111b4cf.png)

```swift
platform :ios, '13.6'
use_frameworks!
target 'Relay22' do
 pod 'Alamofire', '~> 5.2.2'
 pod 'SwiftyJSON'
end
```

![Untitled 4](https://user-images.githubusercontent.com/28242038/90349013-1ff17480-e073-11ea-8aa8-9d5ac033ba34.png)

```swift
//
//  GreyToColorViewController.swift
//  Relay22
//
//  Created by kante on 2020/08/14.
//  Copyright Â© 2020 gicho. All rights reserved.
//

import UIKit
import Alamofire
import SwiftyJSON

struct HTTPBinResponse: Decodable { let url: String }

class GreyToColorViewController: UIViewController {
    
    @IBOutlet weak var uploadImage: UIButton!
    @IBOutlet weak var imageView: UIImageView!
    var data: Data?
    var imageData: Data?
    
    convenience init() {
        self.init(nibName: nil, bundle: nil)
        data = nil
        imageData = nil
    }
    
    override func viewDidLoad() {
        super.viewDidLoad()
        
        let url = URL(string: "https://cdn.crowdpic.net/list-thumb/thumb_l_2D4CE204F6AC69BBD12954E21F972814.jpg")
        data = try? Data(contentsOf: url!)
        imageView.image = UIImage(data: data!)
        imageData = imageView.image?.jpegData(compressionQuality: 0.50)
    }
    
    
    @IBAction func onClick(_ sender: Any) {
        let headers: HTTPHeaders = [
            "api-key": "186e88d3-bb5c-4682-8d8b-476e247d1511",
            "Accept": "application/json"
        ]
        
        AF.upload(multipartFormData: { multipartFormData in
            multipartFormData.append(self.imageData!, withName: "image", fileName: "greyImage.jpeg", mimeType: "image/jpeg")
        }, to: "https://api.deepai.org/api/colorizer", method: .post, headers: headers)
            .responseJSON { response in
                var json: JSON
                switch response.result{
                case .success(let value):
                    json = JSON(value)
                default: return
                }
                
                let toColorUrlJson = json["output_url"].string
                let toColorUrl = URL(string: toColorUrlJson!)
                let toColorData = try? Data(contentsOf: toColorUrl!)
                self.imageView.image = UIImage(data: toColorData!)
                
        }
    }
}
```

# ê¸°ëŠ¥ 3 : ì–´ë ¤ë³´ì´ê²Œ í•˜ê¸°

### êµ¬ì„±ì›

(ì´ë¦„ ì¨ì£¼ì„¸ìš”)

S060 ìµœë™ê·œ

S011 ê¹€ì‹ ìš°

S024 ì„¤ë¯¼ì£¼

---

# íšŒê³  ë° ì†Œê°

ìµëª…1 : ì‚¬ì§„ì„ ìë¥´ëŠ”ë° JKë‹˜ ì–¼êµ´ì´ ì›ƒìŒë²¨ì´ì˜€ìŠµë‹ˆë‹¤. ì¦ê²ê²Œ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í• ìˆ˜ ìˆì–´ì„œ ì¢‹ì•˜ìŠµë‹ˆë‹¤. 

ìµëª…2 : ì–´ì œ ë¯¸ì…˜ í•˜ëŠë¼ ì ì„ ì œëŒ€ë¡œ ëª»ìì„œ ë„ˆë¬´ í˜ë“¤ì—ˆëŠ”ë° ë‹¤ë“¤ ë„ˆë¬´ ì¬ë°Œê³  ìœ ì¾Œí•´ì„œ ë§ì´ ì›ƒìœ¼ë©´ì„œ í”„ë¡œì íŠ¸ í•  ìˆ˜ ìˆì—ˆë˜ ê²ƒ ê°™ì•„ìš” :) ìµœê³  ê³µì‹ ì€ ì‚¬ì§„ì„ ìë¥´ìë§ˆì ë‚˜ì˜¨ JKë‹˜ ì–¼êµ´ã…ã…ã… ì•„ ì˜¤ëŠ˜ ë„ˆë¬´ ì¬ë°Œë„¤ìš”

ìµëª…3 : ğŸ˜† ì´ë¯¸ì§€ AIë¼ ì–´ë ¤ì› ëŠ”ë°, ì¦ê±°ìš´ íŒ€ì›ë“¤ ë•ë¶„ì— ì‹œê°„ê°€ëŠ”ì§€ ëª¨ë¥´ê³  ì‘ì—…í–ˆë„¤ìš”!! ğŸ˜†

ìµëª…4 : íŒ€ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ í•˜ëŠ”ë° ì´ë ‡ê²Œ ì¦ê±°ìš¸ìˆ˜ ìˆêµ¬ë‚˜...! ë¥¼ ëŠê¼ˆìŠµë‹ˆë‹¤ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹

ìµëª…5 : ì´ë²ˆì£¼ ê°œì¸ë¯¸ì…˜ì´ ì´í•´ê°€ ì˜ ë˜ì§€ì•Šì•„ ì‹œê°„ë„ ë§ì´ ê±¸ë¦¬ê³  í˜ë“¤ì—ˆëŠ”ë° ì˜¤ëŠ˜ ë¦´ë ˆì´ì—ì„œ ìš°ë¦¬ ì¡°ì›ë¶„ë“¤ê³¼ ì¬ë°Œê²Œ ë¦´ë ˆì´ ë¯¸ì…˜ì„ í•  ìˆ˜ ìˆì–´ì„œ í˜ë“¤ì—ˆì§€ë§Œ í˜ë“¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! ğŸ¤£

ìµëª…6: ì§€ê¸ˆ ê¹Œì§€ í•´ì™”ë˜ ë¦´ë ˆì´ í”„ë¡œì íŠ¸ ì¤‘ ê°€ì¥ ì¬ë°Œì—ˆìŠµë‹ˆë‹¤ iOS ì•± ê¸°ëŠ¥ë„ ë§Œë“¤ì–´ë³´ê³  íŒ€ì›ë“¤ê³¼ ì¬ë°Œê²Œ ì¦ê²¼ìŠµë‹ˆë‹¤!!!

ìµëª…7: ì–´ë ¸ì„ì  ì–¼êµ´ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ì„œ ì—´ì‹¬íˆ ë…¸ë ¥í–ˆì§€ë§Œ.... í™˜ê²½ í˜¸í™˜ì„± ë¬¸ì œì—ì„œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë„ˆë¬´ ì•„ì‰½ìŠµë‹ˆë‹¤ ã… ã…  ë‹¤í–‰íˆ ë‹¤ë¥¸ íŒ€ì›ë¶„ë“¤ê»˜ì„œ ê³¼ì œë¥¼ ì™„ë£Œí•´ì£¼ì…¨ìŠµë‹ˆë‹¤.. ë²„ìŠ¤íƒœì›Œì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤..

ìµëª…8 : ì¬ë°Œì—ˆì–´ìš”~~~~~~ ì¬ë°ŒëŠ” ë¦´ë ˆì´ í”„ë¡œì íŠ¸ ~~~~~~

ìµëª…9: ì§‘ë‹¨ ì§€ì„±ì˜ í˜ì„ ë‹¤ì‹œ í•œë²ˆ ê¹¨ë‹«ê²Œ ëœ ë‚ ì´ì—ˆì–´ìš”~ ë‹¤ ê°™ì´ ìœ¼ìŒ°ìœ¼ìŒ°í•˜ëŠ” ê²ƒì´ ê°œì¸ì—ê²Œ ì–¼ë§ˆë‚˜ í° í˜ì´ ë˜ê³  ë„ì›€ì´ ë˜ëŠ”ì§€ ê¹¨ë‹¬ì„ ìˆ˜ ìˆì—ˆë˜ ë‚ ì´ì—ˆë„¤ìš”~!

ìµëª…10 : ì–´ë ¤ë³´ì´ê²Œ í•˜ê¸° ë„ˆë¬´ ì–´ë µë„¤ìš”.. ê·¸ë˜ë„ ì¬ë°Œì—ˆìŠµë‹ˆë‹¤! 

![image_(1)](https://user-images.githubusercontent.com/28242038/90349021-2253ce80-e073-11ea-85ac-f80a48bb8865.png)<img width="1440" alt="Screen_Shot_2020-08-14_at_18 38 20" src="https://user-images.githubusercontent.com/28242038/90349049-37306200-e073-11ea-8102-9c6ca3a7662f.png">

# Reference

- ì‚¬ì§„ ì–¼êµ´ ì¸ì‹
    - [https://life-shelter.tistory.com/132](https://life-shelter.tistory.com/132)
- ì‚¬ì§„ ìë¥´ê¸°
    - [https://developer.apple.com/documentation/coregraphics/cgimage/1454683-cropping](https://developer.apple.com/documentation/coregraphics/cgimage/1454683-cropping)
    - [https://developer.apple.com/documentation/coreimage/cidetector](https://developer.apple.com/documentation/coreimage/cidetector)
- ì‚¬ì§„ í‘ë°± â†’ ì»¬ëŸ¬ ì „í™˜
    - [https://deepai.org/machine-learning-model/colorizer](https://deepai.org/machine-learning-model/colorizer)